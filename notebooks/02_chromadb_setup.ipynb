{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff963e35",
   "metadata": {},
   "source": [
    "# ChromaDB Setup per K-RSS\n",
    "\n",
    "Questo notebook configura **ChromaDB** come vector database per gli embeddings dei video.\n",
    "\n",
    "## Riferimento\n",
    "\n",
    "> *\"We employ sentence-transformers to encode demonstrations into vectors and store them using ChromaDB, which facilitates ANN search during runtime.\"*\n",
    ">\n",
    "> — **Recommender AI Agent: Integrating Large Language Models for Interactive Recommendations**\n",
    "\n",
    "## Stack Tecnologico\n",
    "\n",
    "| Componente | Tecnologia |\n",
    "|------------|------------|\n",
    "| Vector DB | ChromaDB |\n",
    "| Embedding Model | sentence-transformers (all-MiniLM-L6-v2) |\n",
    "| Similarity | Cosine |\n",
    "| Persistenza | Locale su disco |\n",
    "\n",
    "## Nota sulle Performance\n",
    "\n",
    "ChromaDB è stato scelto per la sua **semplicità d'uso** e il **supporto nativo per metadata filtering**, fondamentale per K-RSS (filtrare per categoria, canale, escludere video già visti).\n",
    "\n",
    "> **Sviluppi Futuri:** In caso di scaling a milioni di video, considerare la migrazione a **FAISS** (Facebook AI Similarity Search), che nei benchmark risulta ~80x più veloce per le query. FAISS richiede però una gestione separata dei metadata (es. SQLite o Pandas DataFrame)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0369e88",
   "metadata": {},
   "source": [
    "## 1. Setup e Caricamento Dati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548248b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "# Percorso dati\n",
    "DATA_PATH = Path(\"../data/raw/scraped_videos.json\")\n",
    "if not DATA_PATH.exists():\n",
    "    DATA_PATH = Path(\"/app/data/raw/scraped_videos.json\")  # Docker path\n",
    "\n",
    "print(f\"Data path: {DATA_PATH}\")\n",
    "print(f\"File exists: {DATA_PATH.exists()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6c0ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carica i video scraped\n",
    "with open(DATA_PATH, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "videos = data.get('videos', [])\n",
    "print(f\"Video caricati: {len(videos)}\")\n",
    "\n",
    "# Mostra esempio\n",
    "if videos:\n",
    "    print(f\"\\nEsempio: {videos[0].get('title', 'N/A')[:60]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b554f9bc",
   "metadata": {},
   "source": [
    "## 2. Embedding Model (sentence-transformers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed4a475",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "MODEL_NAME = 'all-MiniLM-L6-v2'  # 384 dim, veloce\n",
    "print(f\"Caricamento modello: {MODEL_NAME}\")\n",
    "\n",
    "model = SentenceTransformer(MODEL_NAME)\n",
    "print(f\"Modello caricato! Dimensione: {model.get_sentence_embedding_dimension()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05557cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_text(video: dict) -> str:\n",
    "    \"\"\"Combina titolo e descrizione per l'embedding.\"\"\"\n",
    "    title = video.get('title', '')\n",
    "    description = video.get('description', '')[:500]\n",
    "    return f\"{title}. {description}\".strip()\n",
    "\n",
    "texts = [prepare_text(v) for v in videos]\n",
    "video_ids = [v.get('video_id', f'video_{i}') for i, v in enumerate(videos)]\n",
    "\n",
    "print(f\"Testi preparati: {len(texts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf9a66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genera embeddings\n",
    "print(\"⏳ Generazione embeddings...\")\n",
    "start_time = time.time()\n",
    "\n",
    "embeddings = model.encode(texts, show_progress_bar=True, convert_to_numpy=True)\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"\\nEmbeddings generati in {elapsed:.2f}s\")\n",
    "print(f\"Shape: {embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7402eb",
   "metadata": {},
   "source": [
    "## 3. ChromaDB Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf0c756",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "\n",
    "# Percorso persistenza\n",
    "CHROMA_PATH = Path(\"../data/embeddings/chroma_db\")\n",
    "if not CHROMA_PATH.parent.exists():\n",
    "    CHROMA_PATH = Path(\"/app/data/embeddings/chroma_db\")\n",
    "CHROMA_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Inizializza client persistente\n",
    "client = chromadb.PersistentClient(path=str(CHROMA_PATH))\n",
    "print(f\"ChromaDB inizializzato: {CHROMA_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4359c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea collection\n",
    "COLLECTION_NAME = \"krss_videos\"\n",
    "\n",
    "# Elimina se esiste (per rieseguire il notebook)\n",
    "try:\n",
    "    client.delete_collection(COLLECTION_NAME)\n",
    "    print(f\"Collection '{COLLECTION_NAME}' eliminata\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "collection = client.create_collection(\n",
    "    name=COLLECTION_NAME,\n",
    "    metadata={\"hnsw:space\": \"cosine\"}\n",
    ")\n",
    "print(f\"Collection '{COLLECTION_NAME}' creata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6138a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepara metadata per ogni video\n",
    "metadatas = []\n",
    "for v in videos:\n",
    "    metadatas.append({\n",
    "        \"channel_id\": v.get(\"channel_id\", \"\"),\n",
    "        \"channel_name\": v.get(\"channel_name\", \"\"),\n",
    "        \"category\": v.get(\"category_name\", \"Unknown\"),\n",
    "        \"published_at\": v.get(\"published_at\", \"\"),\n",
    "    })\n",
    "\n",
    "# Inserisci tutto\n",
    "print(\"⏳ Inserimento in ChromaDB...\")\n",
    "start_time = time.time()\n",
    "\n",
    "collection.add(\n",
    "    ids=video_ids,\n",
    "    embeddings=embeddings.tolist(),\n",
    "    documents=texts,\n",
    "    metadatas=metadatas\n",
    ")\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"Inseriti {collection.count()} video in {elapsed:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c5cd85",
   "metadata": {},
   "source": [
    "## 4. Test Ricerca per Similarità"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d1e509",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_videos(query: str, n_results: int = 5, category_filter: str = None):\n",
    "    \"\"\"Cerca video simili alla query.\"\"\"\n",
    "    query_embedding = model.encode([query])[0].tolist()\n",
    "    \n",
    "    where_filter = {\"category\": category_filter} if category_filter else None\n",
    "    \n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_embedding],\n",
    "        n_results=n_results,\n",
    "        where=where_filter,\n",
    "        include=[\"documents\", \"metadatas\", \"distances\"]\n",
    "    )\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab42c5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test ricerca\n",
    "query = \"machine learning tutorial\"\n",
    "print(f\"Query: '{query}'\\n\")\n",
    "\n",
    "results = search_videos(query, n_results=5)\n",
    "\n",
    "print(\"Risultati:\")\n",
    "for i, (doc, meta, dist) in enumerate(zip(\n",
    "    results['documents'][0], \n",
    "    results['metadatas'][0], \n",
    "    results['distances'][0]\n",
    ")):\n",
    "    similarity = 1 - dist\n",
    "    print(f\"\\n{i+1}. [{similarity:.3f}] {doc[:70]}...\")\n",
    "    print(f\"\\t{meta.get('channel_name', 'N/A')} | {meta.get('category', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e7d6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test con filtro categoria\n",
    "print(\"Ricerca con filtro categoria 'Education':\")\n",
    "results_filtered = search_videos(query, n_results=3, category_filter=\"Education\")\n",
    "\n",
    "for doc, meta in zip(results_filtered['documents'][0], results_filtered['metadatas'][0]):\n",
    "    print(f\"  • {doc[:60]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84bc05f",
   "metadata": {},
   "source": [
    "## 5. Configurazione Finale\n",
    "\n",
    "Questa configurazione verrà usata nel modulo `AI_RM`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a49a5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    \"vector_db\": \"ChromaDB\",\n",
    "    \"embedding_model\": \"all-MiniLM-L6-v2\",\n",
    "    \"embedding_dimension\": 384,\n",
    "    \"similarity_metric\": \"cosine\",\n",
    "    \"persistence_path\": \"data/embeddings/chroma_db\",\n",
    "    \"collection_name\": \"krss_videos\",\n",
    "    \"metadata_fields\": [\"channel_id\", \"channel_name\", \"category\", \"published_at\"]\n",
    "}\n",
    "\n",
    "print(\"Configurazione K-RSS:\")\n",
    "print(json.dumps(CONFIG, indent=2))\n",
    "\n",
    "print(\"\\nSetup completato!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
